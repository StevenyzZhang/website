<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yanzhe Zhang</title>
  
  <meta name="author" content="Yanzhe Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/gatech.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>张彦哲 (Yanzhe Zhang)</name>
              </p>
              <p> 
                I am a final-year computer science Ph.D. student at <a href="https://www.ic.gatech.edu/">Georgia Tech</a>, working with <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>. 
              </p>
              <p>
              I am visiting <a href="https://nlp.stanford.edu/">Stanford NLP</a> now.
              </p>
              <p>
              I received my bachelor's degree from <a href="http://www.en.cs.zju.edu.cn/">Zhejiang University</a> in 2021.
              </p>
              <p> I interned at Adobe Research (2022-2023) with <a href="https://zhangry868.github.io/">Ruiyi Zhang</a>.
              </p>
              <p> Fun fact: मेरा नाम संजू (Sanju) है. I also go by Steven.</p>
              <p style="text-align:center">
                <a href="mailto:z_yanzhe@gatech.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=iJImxvUAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/StevenyzZhang/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
            <img style="width:100%;max-width:100%" alt="profile photo" src="images/new_touxiang.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p>
              My research focuses on how to build AI agents that <strong>reshape human-AI interaction</strong> and how to deploy them <strong>safely at scale</strong>.
              </p> 
            </td>
          </tr>
        </tbody></table>

        <table class="publications" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2508.19227">
                <papertitle>Generative Interfaces for Language Models</papertitle>
              </a>
              <br>
              <a>Jiaqi Chen*</a>,
              <strong>Yanzhe Zhang*</strong>,
              <a>Yutong Zhang</a>,
              <a>Yijia Shao</a>,
              <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>
              <br>
              <em>Preprint</em> &nbsp;&nbsp;[<a href="https://github.com/SALT-NLP/GenUI">code</a>] [<a href="https://salt-nlp.github.io/generative_interfaces/">website</a>]
            </td>
          </tr>
          <tr>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2508.10880">
                  <papertitle>Searching for Privacy Risks in LLM Agents via Simulation</papertitle>
                </a>
                <br>
                <strong>Yanzhe Zhang</strong>,
                <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>
                <br>
                <em>ICLR</em>, 2026 &nbsp;&nbsp;[<a href="https://github.com/SALT-NLP/search_privacy_risk">code</a>]
              </td>
            </tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2512.17267">
                <papertitle>AutoMetrics: Approximate Human Judgements with Automatically Generated Evaluators</papertitle>
              </a>
              <br>
              <a>Michael J. Ryan</a>,
              <strong>Yanzhe Zhang</strong>,
              <a>Amol Salunkhe</a>,
              <a>Yi Chu</a>,
              <a>Di Xu</a>,
              <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>
              <br>
              <em>ICLR</em>, 2026 &nbsp;&nbsp;[<a href="https://github.com/SALT-NLP/autometrics">code</a>]
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2511.04898">
                <papertitle>Real-Time Reasoning Agents in Evolving Environments</papertitle>
              </a>
              <br>
              <a>Yule Wen*</a>,
              <a>Yixin Ye*</a>,
              <strong>Yanzhe Zhang</strong>,
              <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>,
              <a>Hao Zhu</a>
              <br>
              <em>ICLR</em>, 2026 &nbsp;&nbsp;[<a href="https://github.com/SALT-NLP/RealtimeGym">code</a>]
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=3x4SDbXbgl">
                <papertitle>Computer Agent Arena: Toward Human-Centric Evaluation and Analysis of Computer-Use Agents</papertitle>
              </a>
              <br>
              <a>Bowen Wang</a>,
              <a>Xinyuan Wang</a>,
              <a>Jiaqi Deng</a>,
              <a>Tianbao Xie</a>,
              <a>Ryan Li</a>,
              <strong>Yanzhe Zhang</strong>,
              <a>Junli Wang</a>,
              <a>Dunjie Lu</a>,
              <a>Zicheng Gong</a>,
              <a>Gavin Li</a>,
              <a>Toh Jing Hua</a>,
              <a>Wei-Lin Chiang</a>,
              <a>Ion Stoica</a>,
              <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>,
              <a>Yu Su</a>,
              <a>Yi Zhang</a>,
              <a>Zhiguo Wang</a>,
              <a>Victor Zhong</a>,
              <a href="https://taoyds.github.io/">Tao Yu</a>
              <br>
              <em>ICLR</em>, 2026 &nbsp;&nbsp;[<a href="https://github.com/xlang-ai/computer-agent-arena">code</a>]
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2504.21798">
                <papertitle>SWE-smith: Scaling Data for Software Engineering Agents</papertitle>
              </a>
              <br>
              <a>John Yang</a>,
              <a>Kilian Lieret</a>,
              <a>Carlos E. Jimenez</a>,
              <a>Alexander Wettig</a>,
              <a>Kabir Khandpur</a>,
              <strong>Yanzhe Zhang</strong>,
              <a>Binyuan Hui</a>,
              <a>Ofir Press</a>,
              <a>Ludwig Schmidt</a>,
              <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>
              <br>
              <em>NeurIPS Datasets &amp; Benchmarks</em>, 2025 &nbsp;&nbsp;[<a href="https://swesmith.com/">website</a>]
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2411.02391">
                <papertitle>Attacking Vision-Language Computer Agents via Pop-ups</papertitle>
              </a>
              <br>
              <strong>Yanzhe Zhang</strong>,
              <a href="https://taoyds.github.io/">Tao Yu</a>,
              <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>
              <br>
              <em>ACL</em>, 2025 &nbsp;&nbsp;[<a href="https://github.com/SALT-NLP/PopupAttack">code</a>]
            </td>
          </tr>

        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <a href="https://aclanthology.org/2025.acl-long.388/">
              <papertitle>Distilling an End-to-End Voice Assistant from Speech Recognition Data</papertitle>
            </a>
            <br>
            <a href="https://williamheld.com/">Will Held</a>,
            <strong>Yanzhe Zhang</strong>,
            <a>Ella Li</a>,
            <a href="https://wyshi.github.io/">Weiyan Shi</a>,
            <a>Michael Ryan</a>,
            <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>
            <br>
            <em>ACL</em>, 2025 &nbsp;&nbsp;[<a href="https://diva-audio.github.io/">website</a>][<a href="https://github.com/Helw150/levanter/blob/will/distill/src/levanter/models/via.py">training code</a>][<a href="https://colab.research.google.com/drive/1Ab3z_BjM_FblAyne7W7hbnT6gLWOhram?usp=sharing">eval code</a>]
          </td>
        </tr>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2410.16232">
                <papertitle>Sketch2Code: Evaluating Vision-Language Models for Interactive Web Design Prototyping</papertitle>
              </a>
              <br>
              <a>Ryan Li</a>,
              <strong>Yanzhe Zhang</strong>,
              <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>
              <br>
              <em>NAACL</em>, 2025 &nbsp;&nbsp;[<a href="https://salt-nlp.github.io/Sketch2Code-Project-Page/">website</a>][<a href="https://github.com/SALT-NLP/Sketch2Code">code</a>]
            </td>
          </tr>

        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2403.03163">
              <papertitle>Design2Code: How Far Are We From Automating Front-End Engineering?</papertitle>
            </a>
            <br>
            <a href="https://noviscl.github.io/">Chenglei Si*</a>,
            <strong> Yanzhe Zhang* </strong>,
            <a>Ryan Li</a>,
            <a>Zhengyuan Yang</a>,
            <a>Ruibo Liu</a>,
            <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>
            <br>
            <em>NAACL</em>, 2025 &nbsp;&nbsp;[<a href="https://salt-nlp.github.io/Design2Code/">website</a>][<a href="https://github.com/NoviScl/Design2Code">code</a>][<a href="https://huggingface.co/datasets/SALT-NLP/Design2Code-hf">data</a>]
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2310.02170">
              <papertitle>Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with Agent Evaluation</papertitle>
            </a>
            <br>
            <a href="https://www.semanticscholar.org/author/Zijun-Liu/2117942065">Zijun Liu</a>,
            <strong> Yanzhe Zhang </strong>, 
	          <a href="http://www.lpeng.net/">Peng Li</a>,
            <a href="http://nlp.csai.tsinghua.edu.cn/~ly/">Yang Liu</a>,
            <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>
            <br>
            <em>COLM</em>, 2024 &nbsp;&nbsp;[<a href="https://github.com/SALT-NLP/DyLAN">code</a>]
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2302.03675">
              <papertitle>Auditing Gender Presentation Differences in Text-to-Image Models</papertitle>
            </a>
            <br>
            <strong> Yanzhe Zhang </strong>, 
	          <a href="http://www.lujiang.info/index.html">Lu Jiang</a>,
            <a href="https://faculty.cc.gatech.edu/~turk/">Greg Turk</a>,
            <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>
            <br>
            <em>EAAMO</em>, 2024 &nbsp;&nbsp;[<a href="https://salt-nlp.github.io/GEP/">website</a>][<a href="https://github.com/SALT-NLP/GEP_data">code</a>][<a href="https://github.com/SALT-NLP/GEP_data">data</a>]
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <a href="https://ieeexplore.ieee.org/document/10656247">
              <papertitle>TRINS: Towards Multimodal Language Models that Can Read</papertitle>
            </a>
            <br>
            <a href="https://zhangry868.github.io/">Ruiyi Zhang</a>,
            <strong>Yanzhe Zhang</strong>,
            <a>Jian Chen</a>,
            <a href="https://yufanzhou.com/">Yufan Zhou</a>,
            <a href="https://gujiuxiang.com/">Jiuxiang Gu</a>,
            <a>Changyou Chen</a>,
            <a href="https://research.adobe.com/person/tong-sun/">Tong Sun</a>
            <br>
            <em>CVPR</em>, 2024
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2306.17107">
              <papertitle>Enhanced Visual Instruction Tuning for Text-rich Image Understanding</papertitle>
            </a>
            <br>
            <strong> Yanzhe Zhang </strong>, 
	          <a href="https://zhangry868.github.io/">Ruiyi Zhang</a>,
            <a href="https://gujiuxiang.com/">Jiuxiang Gu</a>,
            <a href="https://yufanzhou.com/">Yufan Zhou</a>,
            <a href="https://research.adobe.com/person/nedim-lipka/">Nedim Lipka</a>,
            <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>,
            <a href="https://research.adobe.com/person/tong-sun/">Tong Sun</a>
            <br>
            <em>NeurIPS Workshop on Instruction Tuning and Instruction Following</em>, 2023 &nbsp;&nbsp;[<a href="https://llavar.github.io/">website</a>][<a href="https://github.com/SALT-NLP/LLaVAR">code</a>][<a href="https://huggingface.co/datasets/SALT-NLP/LLaVAR">data</a>]
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2210.10693">
              <papertitle>Robustness of Demonstration-based Learning Under Limited Data Scenario</papertitle>
            </a>
            <br>
            <a href="https://icefoxzhx.github.io/">Hongxin Zhang</a>,
            <strong> Yanzhe Zhang </strong>, 
            <a href="https://zhangry868.github.io/">Ruiyi Zhang</a>,
            <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>
            <br>
            <em>EMNLP</em>, 2022 &nbsp;&nbsp;[<a href="https://github.com/SALT-NLP/RobustDemo">code</a>]
          </td>
        </tr>
        
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2203.10652">
                <papertitle>Continual Sequence Generation with Adaptive Compositional Modules</papertitle>
              </a>
              <br>
              <strong> Yanzhe Zhang </strong>, 
	            <a href="https://scholar.google.com/citations?user=ScLUQ-YAAAAJ&hl=en">Xuezhi Wang</a>,
              <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>
              <br>
              <em>ACL</em>, 2022 &nbsp;&nbsp;[<a href="https://github.com/SALT-NLP/Adaptive-Compositional-Modules">code</a>]
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://aclanthology.org/2021.naacl-main.218/">
                <papertitle>Continual Learning for Text Classification with Information Disentanglement Based Regularization</papertitle>
              </a>
              <br>
              <a href="https://codeforces.com/profile/yfhuang">Yufan Huang*</a>,
              <strong> Yanzhe Zhang* </strong>, 
              <a href="https://www.jiaaochen.com/">Jiaao Chen</a>,
	            <a href="https://scholar.google.com/citations?user=ScLUQ-YAAAAJ&hl=en">Xuezhi Wang</a>,
              <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>
              <br>
              <em>NAACL</em>, 2021 &nbsp;&nbsp;[<a href="https://github.com/SALT-NLP/IDBR">code</a>]
            </td>
          </tr>

        </tbody></table>

				<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Service</heading>
            <p>
              <strong>Reviewer:</strong> ARR, ACL, NAACL, EMNLP, EACL, COLM, CoLLAs, ICLR, ICML.
            </p>
          </td>
        </tr>
      </tbody></table>
        
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Website's code is from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
